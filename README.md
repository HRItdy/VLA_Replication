# VLA_Replication
All files need to be updated. The newest version is on the remote training server.

## Dataset conversion
We used Diffusion policy to collect data, and use https://github.com/kpertsch/rlds_dataset_builder to build rlds dataset.
1. Create a folder, put the builder `robo_ur_screwdriver_dataset_builder.py` in.
2. Build it.
   The generated dataset will be like:
   
![Screenshot from 2025-05-24 15-44-33](https://github.com/user-attachments/assets/6bf5574b-680b-42cc-ac5b-a4a6fb6b3841)

If it said there is already one dataset exists, delete all the generated items (verify, forget. There should be a chat in GPT or Claude.)

## OpenVLA
1. The main thing is to register the dataset, define the structure (key-value mapping) of different rlds datasets (shown in the config.py).

2. Use `openvla/vla-scripts/deploy.py` to establish the server.
   ```
   Note that if your server is not accessible on the open web, you can use ngrok, or forward ports to your client via ssh:
    => `ssh -L 8000:localhost:8000 ssh USER@<SERVER_IP>`
   ```
## RDT-1b
1. Define the dataset according to instructions in the original repo (the control frequence is 10Hz according to the data collection code in DP).

2. Refer to `configs/state_vec.py` to get the index of the state vector where different dimensions should be placed. RDT-1b provides an unified state vector. Our own dataset should be put the fixed position in this state vector (refer to the code in the remote server.)
## $\pi_0$
(https://github.com/Physical-Intelligence/openpi)

1. You need to define the task configure somewhere (refer to the remote code)

2. Use `pi0_data_conversion.py` to convert h5 to libero dataset.

3. `packages/openpi-client/src/openpi_client/websocket_client_policy.py` to establish the server. Similarly, need to handleover the port through ssh. Instruction: https://github.com/Physical-Intelligence/openpi/blob/main/docs/remote_inference.md

4. https://github.com/Physical-Intelligence/openpi/blob/main/examples/libero/README.md Instructions to directly run finetuned openpi on libero simulation dataset.

## Diffusion Policy
https://github.com/real-stanford/diffusion_policy

1. Comply with the hardware requirements. Then run `diffusion_policy/diffusion_policy/demo_real_robot.py` to teleoperate UR5 with SpaceMouse.

2. The data converting the collected dataset to replaybuffer is in `diffusion_policy/diffusion_policy/real_world/real_data_conversion.py`. The structure is like:
![Screenshot from 2025-05-24 14-27-57](https://github.com/user-attachments/assets/ad8eedb2-1614-470c-9792-650f9b1aece3)

3. We provide a script to convert .zarr dataset to h5py dataset: `diffusion_policy/diffusion_policy/real_world/dataset_conversion.py`.

4. This code uses yaml to recursively define the task. Please change yaml in task to aligh it with your own dataset, and policy relevant yaml to define the policy to call.

5. We provide `visualize.py` to visualize the video in the converted dataset, help users to identify whether the converted dataset is consistant with the original one. Meanwhile, `wandb_drawer.py` is provided to users to consolidate the training results from different wandb projects and json files into one paper-style figure.
## Action Chunking Transformer
https://github.com/Shaka-Labs/ACT
1. First align the dimension of `state_dim` of vae and the training dataet.
   When installed ACT you should also installed `detr`, go to `detr->models->detr_vae.py`, change line 230 to the demension of your training dataset.

   Another way to open this is directing to `training->policy.py', go to definition of `build_ACT_model_and_optimizer->build_ACT_model->build_vae`.

2. Second need to padding all the episodes to the fixed length, which is defined in `ACT/config/config.py` as `episode_len` in `TASK_CONFIG`. Please run the code in `dataset_preproc.py` under ACT folder, which will pad all of your episodes in the dataset to the predefined `episode_len`.

3. Put the dataset with **hdf5** format under `data` folder
```
├── data
│   └── pick_screwdriver
│       ├── screwdriver
│       │   ├── episode_0.hdf5
│       │   ├── episode_1.hdf5
│       │   ├── episode_2.hdf5
│       │   ├── ...
│       └── text_embed
│           └── embed_0.pt
```
Forget whether need to put text embedding inside (generated by feed the task instruction like `pick up the screwdriver` into t5). If some error meaning the number of episodes is not correct raises, then delete it.

4. Run `python train.py --task sort`. Change `sort` to the name of your dataset folder (`pick_screwdriver` in my case).

## Evaluation
1. We provide `UR5_test_ACT.py`, `UR5_test_openvla.py` and `UR5_test_openpi.py` for onsite inference. Expect for ACT, other two models please refer to the previous sections to identify how to establish the server.

